{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wine RNNTinderProfileGeneration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtzZORs9pZUr",
        "colab_type": "text"
      },
      "source": [
        "# Tinder profile generation with RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtMF6Q6-pY5r",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Part of the Tinder profile generation project\n",
        "This section handles the profile text generation using LSTMs\n",
        "we use the kaggle TInder dataset at https://www.kaggle.com/immune/tinder-profiles\n",
        "\n",
        "\n",
        "Based primary on Brownlees tutorial\n",
        "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
        "@author: Adrian\n",
        "\n",
        "DONT FORGET TO GET RANDOM SEED GEN FROM TRUMP OR BROWNLEE\n",
        "\n",
        "Brownlees tutorial helps with understanding, but for actual generation, Trump CharRNN is much more useful\n",
        "https://github.com/jctestud/char-rnn/blob/master/char-rnn_trump_text_generation-TRAINING.ipynb\n",
        "\n",
        "TLDR: Uses a certain length of chars to predict the next char in a Bio, trained on over 40K Bios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5TFQI0Cppx1",
        "colab_type": "code",
        "outputId": "6913e459-c552-4e2f-917d-552abc859cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#Import all packages\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import warnings\n",
        "import sklearn\n",
        "import io\n",
        "import scipy\n",
        "import numpy\n",
        "import json\n",
        "import nltk\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Activation, Dense\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1A8zyqs9j-kS1oE2xUhhFSRe0UGEtp_sc\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A8zyqs9j-kS1oE2xUhhFSRe0UGEtp_sc\n",
            "To: /content/wine.csv\n",
            "5.01MB [00:00, 15.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OdDzt7wpwUH",
        "colab_type": "code",
        "outputId": "db6e7d7d-8c0e-4ef1-b650-bcd84e287194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1619
        }
      },
      "source": [
        "#Text import and preprocessing\n",
        "base_dir = 'wine.csv'\n",
        "\n",
        "\n",
        "tinder_profile_df = pd.read_csv(base_dir)\n",
        "\n",
        "# Print dataframe info\n",
        "tinder_profile_df.info()\n",
        "\n",
        "print(tinder_profile_df.head())\n",
        "\n",
        "# This will print the number of rows and columns that will be used to train\n",
        "print(\"Shape of train set : \",tinder_profile_df.shape)\n",
        "\n",
        "#tinder_profile_df.head()\n",
        "\n",
        "#Convert dataframe to string already here\n",
        "\n",
        "tinder_bios_df=tinder_profile_df['description'].apply(str)\n",
        "\n",
        "\n",
        "\n",
        "#Print only thhe bios\n",
        "print(tinder_bios_df)\n",
        "\n",
        "#Define a generic vocabulary\n",
        "# generic vocabulary\n",
        "characters = list(string.printable)\n",
        "characters.remove('\\x0b')\n",
        "characters.remove('\\x0c')\n",
        "\n",
        "VOCABULARY_SIZE = len(characters)\n",
        "characters_to_ix = {c:i for i,c in enumerate(characters)}\n",
        "print(\"vocabulary len = %d\" % VOCABULARY_SIZE)\n",
        "print(characters)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15092 entries, 0 to 15091\n",
            "Data columns (total 11 columns):\n",
            "Unnamed: 0     15092 non-null int64\n",
            "country        15090 non-null object\n",
            "description    15092 non-null object\n",
            "designation    10747 non-null object\n",
            "points         15092 non-null int64\n",
            "price          14160 non-null float64\n",
            "province       15090 non-null object\n",
            "region_1       12821 non-null object\n",
            "region_2       5871 non-null object\n",
            "variety        15092 non-null object\n",
            "winery         15092 non-null object\n",
            "dtypes: float64(1), int64(2), object(8)\n",
            "memory usage: 1.3+ MB\n",
            "   Unnamed: 0 country  ...             variety                   winery\n",
            "0           0      US  ...  Cabernet Sauvignon                    Heitz\n",
            "1           1   Spain  ...       Tinta de Toro  Bodega Carmen Rodríguez\n",
            "2           2      US  ...     Sauvignon Blanc                 Macauley\n",
            "3           3      US  ...          Pinot Noir                    Ponzi\n",
            "4           4  France  ...  Provence red blend     Domaine de la Bégude\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Shape of train set :  (15092, 11)\n",
            "0        This tremendous 100% varietal wine hails from ...\n",
            "1        Ripe aromas of fig, blackberry and cassis are ...\n",
            "2        Mac Watson honors the memory of a wine once ma...\n",
            "3        This spent 20 months in 30% new French oak, an...\n",
            "4        This is the top wine from La Bégude, named aft...\n",
            "5        Deep, dense and pure from the opening bell, th...\n",
            "6        Slightly gritty black-fruit aromas include a s...\n",
            "7        Lush cedary black-fruit aromas are luxe and of...\n",
            "8        This re-named vineyard was formerly bottled as...\n",
            "9        The producer sources from two blocks of the vi...\n",
            "10       Elegance, complexity and structure come togeth...\n",
            "11       From 18-year-old vines, this supple well-balan...\n",
            "12       A standout even in this terrific lineup of 201...\n",
            "13       This wine is in peak condition. The tannins an...\n",
            "14       With its sophisticated mix of mineral, acid an...\n",
            "15       First made in 2006, this succulent luscious Ch...\n",
            "16       This blockbuster, powerhouse of a wine suggest...\n",
            "17       Nicely oaked blackberry, licorice, vanilla and...\n",
            "18       Coming from a seven-acre vineyard named after ...\n",
            "19       This fresh and lively medium-bodied wine is be...\n",
            "20       Heitz has made this stellar rosé from the rare...\n",
            "21       Alluring, complex and powerful aromas of grill...\n",
            "22       Tarry blackberry and cheesy oak aromas are app...\n",
            "23       The apogee of this ambitious winery's white wi...\n",
            "24       San Jose-based producer Adam Comartin heads 1,...\n",
            "25       Yields were down in 2015, but intensity is up,...\n",
            "26       Bergström has made a Shea designate since 2003...\n",
            "27       Focused and dense, this intense wine captures ...\n",
            "28       Cranberry, baked rhubarb, anise and crushed sl...\n",
            "29       This standout Rocks District wine brings earth...\n",
            "                               ...                        \n",
            "15062    “Rotschiefer” means “red slate,” a reference t...\n",
            "15063    No malo in this tight, acidic young wine. It's...\n",
            "15064    Blackberries and blueberries star on the palat...\n",
            "15065    Nicely done for an entry-level wine, with love...\n",
            "15066    Released along with the '02, this wine still t...\n",
            "15067    Nicely captures Pinot's delicacy and silkiness...\n",
            "15068    Part of a growing trend among German wines, th...\n",
            "15069    Oakier than Tscheppe's regular bottling but ul...\n",
            "15070    Still hard and tough in tannins, but that's Mo...\n",
            "15071    Made by Charles Cimicky, who apparently also h...\n",
            "15072    On the light side, but not lacking for concent...\n",
            "15073    The Czerny family, who have 27 acres of vines ...\n",
            "15074    Subtle spice and candied cherries on the nose ...\n",
            "15075    Smells like ultraripe nectarines or peaches, f...\n",
            "15076    Very ripe, in fact, shows signs of overripenes...\n",
            "15077    This isn't a wine to age or mull over, but I l...\n",
            "15078    Another nice GV from Allram—and at an excellen...\n",
            "15079    Smells like a dessert wine, with apricot, smok...\n",
            "15080    A full-bodied wine, with aromas of apples and ...\n",
            "15081    Oak lends nutty, caroby aromas and big, woodsy...\n",
            "15082    Smells meaty, with a streak of eucalyptus. Tau...\n",
            "15083    This wine gets full credit for its smooth, era...\n",
            "15084    Much better than a bottle previously reviewed,...\n",
            "15085    Classic BV Rutherford, with its thick, dusty t...\n",
            "15086    The first wine I've had from the new vintage i...\n",
            "15087    Soft and mouthfilling, with apple, pear, citru...\n",
            "15088    Very ripe in berry fruit, but dry, with a firm...\n",
            "15089    Cool-climate Chard, with crisp, outspoken acid...\n",
            "15090    A spare, austere, lemony sort of Sauvignon.It ...\n",
            "15091    This year Byington blended in some Syrah with ...\n",
            "Name: description, Length: 15092, dtype: object\n",
            "vocabulary len = 98\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ' ', '\\t', '\\n', '\\r']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5bvB2WZqDGS",
        "colab_type": "code",
        "outputId": "e771d091-fc4a-4080-a50e-c187de29f68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#Extract individual bios into one large string\n",
        "\n",
        "#Usually We would pad our sequences, but a quick inspection reveals sequences are drastically different lenghts\n",
        "#hence lets just join them together.\n",
        "#We define a filtering function first\n",
        "holder = []\n",
        "for i in range(0, len(tinder_bios_df)):\n",
        "    #print (tinder_bios_df.iloc[i]);\n",
        "    string = tinder_bios_df.iloc[i]\n",
        "\n",
        "    if(string== \"nan\"):\n",
        "        print(\"nan detected, moving on\")\n",
        "    else:\n",
        "        holder.append(string)\n",
        "\n",
        "#print(holder) \n",
        "\n",
        "alphaholder= []\n",
        "regex = re.compile('[^A-Za-z0-9 -.,]')\n",
        "#now that holder is ready we remove all non alphanumeric entries\n",
        "for i in range(0, len(holder)):\n",
        "    string = holder[i]\n",
        "    \n",
        "    \n",
        "    #First parameter is the replacement, second parameter is your input string\n",
        "    newstring = regex.sub('', string)\n",
        "\n",
        "    alphaholder.append(newstring)\n",
        "    \n",
        "    \n",
        "#print(alphaholder)\n",
        "\n",
        "#Split data into train and validation strings\n",
        "trainholder=[]\n",
        "validationholder=[]\n",
        "\n",
        "print(len(alphaholder))\n",
        "#Len alphaholder is 43660\n",
        "for i in range(0, 12000): \n",
        "    trainstring = alphaholder[i]\n",
        "    trainholder.append(trainstring)\n",
        "for i in range(12000, len(alphaholder)): \n",
        "    valstring = alphaholder[i]\n",
        "    validationholder.append(valstring)\n",
        "\n",
        "\n",
        "#14-04-2019 Data is now ready, need to append into giant string\n",
        "finalstring = ''.join(trainholder)\n",
        "validationstring = ''.join(validationholder)\n",
        "\n",
        "print(finalstring)\n",
        "print(validationstring)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1GbKdFYqO41",
        "colab_type": "text"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x3qGOqAqSul",
        "colab_type": "code",
        "outputId": "7551aba4-d7ad-43c6-8fcb-3bc29eb23064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#Some variables to set here\n",
        "N_GPU = 1\n",
        "# you can experiment with more GPUs, it gets interesting with a high SEQUENCE_LEN\n",
        "SEQUENCE_LEN = 20; \n",
        "#This is the char length of each individual sequence\n",
        "#Essentially, we use 60 chars to predict the 61st char. This needs to be shorter for us\n",
        "BATCH_SIZE = 512 #Number of sequences fed at once in batch\n",
        "EPOCHS = 10\n",
        "HIDDEN_LAYERS_DIM = 512\n",
        "LAYER_COUNT = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "text_train_len = len(finalstring)\n",
        "text_val_len = len(validationstring)\n",
        "def describe_batch(X, y, samples=3):\n",
        "    \"\"\"Describe in a human-readable format some samples from a batch.  Show the next char given previous char\"\"\"\n",
        "    for i in range(samples):\n",
        "        sentence = \"\"\n",
        "        for s in range(SEQUENCE_LEN):\n",
        "            sentence += characters[X[i,s,:].argmax()]\n",
        "        next_char = characters[y[i,:].argmax()]\n",
        "        \n",
        "        print(\"sample #%d: ...%s -> '%s'\" % (\n",
        "            i,\n",
        "            sentence[-20:],\n",
        "            next_char\n",
        "        ))\n",
        "    \n",
        "def batch_generator(text, count):\n",
        "    \"\"\"Generate batches for training\"\"\"\n",
        "    while True: # keras wants that for reasons\n",
        "        for batch_ix in range(count):\n",
        "            X = np.zeros((BATCH_SIZE, SEQUENCE_LEN, VOCABULARY_SIZE))\n",
        "            y = np.zeros((BATCH_SIZE, VOCABULARY_SIZE))\n",
        "\n",
        "            batch_offset = BATCH_SIZE * batch_ix\n",
        "\n",
        "            for sample_ix in range(BATCH_SIZE):\n",
        "                sample_start = batch_offset + sample_ix\n",
        "                for s in range(SEQUENCE_LEN):\n",
        "                    X[sample_ix, s, characters_to_ix[text[sample_start+s]]] = 1\n",
        "                y[sample_ix, characters_to_ix[text[sample_start+s+1]]]=1\n",
        "\n",
        "            yield X, y\n",
        "            \n",
        "\n",
        "\n",
        "for ix, (X,y) in enumerate(batch_generator(finalstring, count=1)):\n",
        "    # describe some samples from the first batch\n",
        "    describe_batch(X, y, samples=5)\n",
        "    break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample #0: ...This tremendous 100% -> ' '\n",
            "sample #1: ...his tremendous 100%  -> 'v'\n",
            "sample #2: ...is tremendous 100% v -> 'a'\n",
            "sample #3: ...s tremendous 100% va -> 'r'\n",
            "sample #4: ... tremendous 100% var -> 'i'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD7I3Td-qb0q",
        "colab_type": "code",
        "outputId": "7d100307-f8d8-485b-99f3-a4218fb1e854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "###########################################Model Building#################################\n",
        "    ###From trump char builder\n",
        "def build_model(gpu_count=1):\n",
        "    \"\"\"Build a Keras sequential model for training the char-rnn\"\"\"\n",
        "    model = Sequential()\n",
        "    for i in range(LAYER_COUNT):\n",
        "        model.add(\n",
        "            LSTM(\n",
        "                HIDDEN_LAYERS_DIM, \n",
        "                return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
        "                input_shape=(SEQUENCE_LEN, VOCABULARY_SIZE),\n",
        "            )\n",
        "        )\n",
        "        model.add(Dropout(DROPOUT))\n",
        "    \n",
        "    model.add(Dense(VOCABULARY_SIZE))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    #removed the multigpu line\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "    return model\n",
        "\n",
        "\n",
        "training_model = build_model(gpu_count=N_GPU)\n",
        "\n",
        "train_batch_count = (text_train_len - SEQUENCE_LEN) // BATCH_SIZE\n",
        "val_batch_count = (text_val_len - SEQUENCE_LEN) // BATCH_SIZE\n",
        "print(\"training batch count: %d\" % train_batch_count)\n",
        "print(\"validation batch count: %d\" % val_batch_count)\n",
        "\n",
        "\n",
        "#NO CHECKPOINTING IN THIS VERSION, because of simplicity and because our dataset is much smaller"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "training batch count: 5723\n",
            "validation batch count: 1459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFc8403oqhrd",
        "colab_type": "code",
        "outputId": "f6922584-711f-4d6e-91ad-2fbd6cd83f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "history = training_model.fit_generator(\n",
        "    batch_generator(finalstring, count=train_batch_count),\n",
        "    train_batch_count,\n",
        "    max_queue_size=1, # no more than one queued batch in RAM\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=batch_generator(validationstring, count=val_batch_count),\n",
        "    validation_steps=val_batch_count,\n",
        "    initial_epoch=0\n",
        ")\n",
        "training_model.save('basic_LSTM_tindergenv1_4layers_30char.h5')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "5723/5723 [==============================] - 1534s 268ms/step - loss: 1.5168 - val_loss: 1.1563\n",
            "Epoch 2/10\n",
            "5723/5723 [==============================] - 1520s 266ms/step - loss: 1.0724 - val_loss: 1.0235\n",
            "Epoch 3/10\n",
            "5723/5723 [==============================] - 1511s 264ms/step - loss: 0.9936 - val_loss: 0.9781\n",
            "Epoch 4/10\n",
            "5723/5723 [==============================] - 1519s 265ms/step - loss: 0.9522 - val_loss: 0.9545\n",
            "Epoch 5/10\n",
            "5723/5723 [==============================] - 1516s 265ms/step - loss: 0.9259 - val_loss: 0.9406\n",
            "Epoch 6/10\n",
            "5723/5723 [==============================] - 1509s 264ms/step - loss: 0.9072 - val_loss: 0.9298\n",
            "Epoch 7/10\n",
            "5723/5723 [==============================] - 1509s 264ms/step - loss: 0.8931 - val_loss: 0.9217\n",
            "Epoch 8/10\n",
            "5723/5723 [==============================] - 1515s 265ms/step - loss: 0.8825 - val_loss: 0.9158\n",
            "Epoch 9/10\n",
            "5723/5723 [==============================] - 1521s 266ms/step - loss: 0.8729 - val_loss: 0.9109\n",
            "Epoch 10/10\n",
            "5723/5723 [==============================] - 1520s 266ms/step - loss: 0.8655 - val_loss: 0.9078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgFxYvt0tuz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "bacbb63b-9214-467e-8bf5-f303e9418816"
      },
      "source": [
        "#############################################################################################################3\n",
        "###After this we can use the trained model to predict things, and view history variables\n",
        "\n",
        "##Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}